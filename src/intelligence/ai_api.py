"""
Laniakea Protocol - AI API Module
Ù…Ø§Ú˜ÙˆÙ„ API Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø¨Ø²Ø±Ú¯
"""

import os
from typing import Dict, Any, Optional, List
from openai import OpenAI, AsyncOpenAI

# Ú©Ù„Ø§ÛŒÙ†Øª OpenAI Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# OPENAI_API_KEY, OPENAI_BASE_URL

class AI_API:
    """
    ÛŒÚ© Ú©Ù„Ø§ÛŒÙ†Øª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø¨Ø²Ø±Ú¯ Ù…Ø®ØªÙ„Ù
    Ú©Ù‡ Ø§Ø² ÙØ±Ù…Øª API OpenAI Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ (Ù…Ø§Ù†Ù†Ø¯ Gemini, GPT-4, Ùˆ ØºÛŒØ±Ù‡).
    """
    
    def __init__(self, model: str = "gemini-2.5-flash"):
        """
        Args:
            model: Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ (Ù…Ø«Ù„Ø§Ù‹ 'gemini-2.5-flash', 'gpt-4.1-mini')
        """
        self.default_model = model
        
        try:
            self.client = AsyncOpenAI()
            self.sync_client = OpenAI()
            print(f"ğŸ¤– AI API client initialized for model 	'{self.default_model}	'")
        except Exception as e:
            print(f"ğŸ”¥ Failed to initialize AI API client: {e}")
            self.client = None
            self.sync_client = None

    async def generate_text(
        self,
        prompt: str,
        model: Optional[str] = None,
        max_tokens: int = 1500,
        temperature: float = 0.7,
        system_prompt: Optional[str] = None
    ) -> Optional[str]:
        """
        ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†
        
        Args:
            prompt: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
            model: Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ØªØ¹ÛŒÛŒÙ†ØŒ Ø§Ø² Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
            max_tokens: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
            temperature: Ù…ÛŒØ²Ø§Ù† Ø®Ù„Ø§Ù‚ÛŒØª (0.0 ØªØ§ 1.0)
            system_prompt: Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø³ÛŒØ³ØªÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
        
        Returns:
            Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        """
        if not self.client:
            return None

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        try:
            response = await self.client.chat.completions.create(
                model=model or self.default_model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error during text generation: {e}")
            return None

    def generate_text_sync(
        self,
        prompt: str,
        model: Optional[str] = None,
        max_tokens: int = 1500,
        temperature: float = 0.7,
        system_prompt: Optional[str] = None
    ) -> Optional[str]:
        """
        Ù†Ø³Ø®Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† (sync) ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†
        """
        if not self.sync_client:
            return None

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        try:
            response = self.sync_client.chat.completions.create(
                model=model or self.default_model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error during sync text generation: {e}")
            return None

    async def analyze_code(
        self,
        code: str,
        language: str = "python"
    ) -> Optional[Dict[str, Any]]:
        """
        ØªØ­Ù„ÛŒÙ„ ÛŒÚ© Ù‚Ø·Ø¹Ù‡ Ú©Ø¯
        
        Args:
            code: Ú©Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            language: Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ
        
        Returns:
            ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„ Ú©Ø¯ ÛŒØ§ None
        """
        system_prompt = f"You are a code analysis expert. Analyze the following {language} code. Provide a JSON response with fields: 'quality_score' (0-100), 'suggestions' (list of strings), 'complexity' (string: 'low', 'medium', 'high'), and 'summary' (string)."
        
        response_text = await self.generate_text(
            prompt=code,
            system_prompt=system_prompt,
            temperature=0.2
        )
        
        if response_text:
            try:
                import json
                return json.loads(response_text)
            except json.JSONDecodeError:
                print("Failed to parse AI response as JSON")
                return {"summary": response_text}
        return None

# Singleton instance
_ai_api_instance = None

def get_ai_api() -> AI_API:
    """
    Ø¯Ø±ÛŒØ§ÙØª instance ÛŒÚ©ØªØ§ÛŒ AI_API
    """
    global _ai_api_instance
    if _ai_api_instance is None:
        _ai_api_instance = AI_API()
    return _ai_api_instance
